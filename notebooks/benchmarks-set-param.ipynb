{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd00e21",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870f669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the notebook imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# this is the convenience function\n",
    "from autokoopman import auto_koopman\n",
    "# for a complete example, let's create an example dataset using an included benchmark system\n",
    "from autokoopman.benchmark import bio2, fhn, lalo20, prde20, robe21, spring, pendulum, trn_constants\n",
    "from glop import Glop\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import statistics\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d088fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benches = [bio2.Bio2(), fhn.FitzHughNagumo(), lalo20.LaubLoomis(), pendulum.PendulumWithInput(beta=0.05), prde20.ProdDestr(), robe21.RobBench(), spring.Spring(), trn_constants.TRNConstants()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288fbb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(bench, param_dict):\n",
    "    init_states = get_init_states(bench, param_dict[\"train_size\"])\n",
    "    if bench._input_vars:\n",
    "        steps = []\n",
    "        for low, high in zip(bench.input_set_low, bench.input_set_high):\n",
    "            if bench.input_type == \"step\":\n",
    "                params = np.random.uniform(low, high, size=(param_dict[\"train_size\"], 3))\n",
    "                steps += [make_input_step(*p, bench.teval) for p in params]\n",
    "            elif bench.input_type == \"rand\":\n",
    "                steps += [make_random_input(low, high, bench.teval) for i in range(param_dict[\"train_size\"])]\n",
    "            else:\n",
    "                sys.exit(\"Please set an input type for your benchmark\") \n",
    "        #print(steps)\n",
    "        training_data = bench.solve_ivps(initial_states=init_states, inputs=steps, teval=bench.teval)\n",
    "    else:\n",
    "        training_data = bench.solve_ivps(initial_states=init_states,tspan=[0.0, 10.0], \n",
    "                                         sampling_period=param_dict[\"samp_period\"])\n",
    "        \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64f973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_states(bench, size, init_seed=0):\n",
    "    if hasattr(bench, 'init_constrs'):\n",
    "        init_states = []\n",
    "        for i in range(size):\n",
    "            init_state_dict = glop_init_states(bench, i+init_seed)\n",
    "            init_state = []\n",
    "            for name in bench.names:\n",
    "                init_state.append(init_state_dict[name])\n",
    "            init_states.append(init_state)\n",
    "        init_states = np.array(init_states)  \n",
    "    else:\n",
    "        init_states = np.random.uniform(low=bench.init_set_low, \n",
    "                    high=bench.init_set_high, size=(size, len(bench.names)))\n",
    "        \n",
    "    return init_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491af68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glop_init_states(bench, seed):    \n",
    "    constrs = []\n",
    "    for constr in bench.init_constrs:\n",
    "        constrs.append(constr)\n",
    "    for i, (name, init_low, init_high) in enumerate(zip(bench.names, bench.init_set_low, bench.init_set_high)):\n",
    "        low_constr = f\"{name} >= {init_low}\"\n",
    "        high_constr = f\"{name} <= {init_high}\"\n",
    "        constrs.extend([low_constr, high_constr])\n",
    "        \n",
    "    glop = Glop(bench.names, constrs)\n",
    "    pop_item = random.randrange(len(bench.names))\n",
    "    names, init_set_low, init_set_high = copy.deepcopy(bench.names), copy.deepcopy(bench.init_set_low), copy.deepcopy(bench.init_set_high)\n",
    "    names.pop(pop_item)\n",
    "    init_set_low.pop(pop_item)\n",
    "    init_set_high.pop(pop_item)\n",
    "    for i, (name, init_low, init_high) in enumerate(zip(names, init_set_low, init_set_high)):\n",
    "        glop.add_tend_value_obj_fn(name, [init_low, init_high], seed+i)\n",
    "    \n",
    "    glop.minimize()\n",
    "\n",
    "    sol_dict = glop.get_all_sols()    \n",
    "    return sol_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66d24f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectories(bench, iv, samp_period):\n",
    "    # get the model from the experiment results\n",
    "    model = experiment_results['tuned_model']\n",
    "\n",
    "    if bench._input_vars:\n",
    "        test_inp = np.sin(np.linspace(0, 10, 200))\n",
    "\n",
    "        # simulate using the learned model\n",
    "        trajectory = model.solve_ivp(\n",
    "            initial_state=iv,\n",
    "            inputs=test_inp,\n",
    "            teval=bench.teval,\n",
    "        )\n",
    "        # simulate the ground truth for comparison\n",
    "        true_trajectory = bench.solve_ivp(\n",
    "            initial_state=iv,\n",
    "            inputs=test_inp,\n",
    "            teval=bench.teval,\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        # simulate using the learned model\n",
    "        trajectory = model.solve_ivp(\n",
    "            initial_state=iv,\n",
    "            tspan=(0.0, 10.0),\n",
    "            sampling_period=samp_period\n",
    "        )\n",
    "        # simulate the ground truth for comparison\n",
    "        true_trajectory = bench.solve_ivp(\n",
    "            initial_state=iv,\n",
    "            tspan=(0.0, 10.0),\n",
    "            sampling_period=samp_period\n",
    "        )\n",
    "    \n",
    "    return trajectory, true_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad1becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trajectories(bench, num_tests, samp_period):\n",
    "    mses = []\n",
    "    perc_errors = []\n",
    "    for j in range(num_tests):\n",
    "        iv = get_init_states(bench, 1, j+10000)[0]\n",
    "        trajectory, true_trajectory = get_trajectories(bench, iv, samp_period)\n",
    "        mse = mean_squared_error(trajectory.states.T, true_trajectory.states.T)\n",
    "        mses.append(mse)\n",
    "        perc_error = mean_absolute_percentage_error(trajectory.states.T, true_trajectory.states.T)\n",
    "        perc_errors.append(perc_error)\n",
    "            \n",
    "    return statistics.mean(mses), statistics.mean(perc_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a361e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_step(duty, on_amplitude, off_amplitude, teval):\n",
    "    \"\"\"produce a step response input signal for the pendulum\"\"\"\n",
    "    length = len(teval)\n",
    "    inp = np.zeros((length,))\n",
    "    phase_idx = int(length * duty)\n",
    "    inp[:phase_idx] = on_amplitude\n",
    "    inp[phase_idx:] = off_amplitude\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62c03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_input(low, high, teval):\n",
    "    length = len(teval)\n",
    "    inp = np.zeros((length,))\n",
    "    for i in range(len(inp)):\n",
    "        inp[i] = np.random.uniform(low, high)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08af2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data(row, filename='benches'):\n",
    "    with open('data/benches', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffbc8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data_heads(row, filename='benches'):\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    \n",
    "    with open(f'data/{filename}', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1a3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(trajectory, true_trajectory, var_1, var_2):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # plot the results\n",
    "    if var_2==-1: #plot against time\n",
    "        plt.plot(trajectory.states[:, var_1], label='Trajectory Prediction')\n",
    "        plt.plot(true_trajectory.states[:, var_1], label='Ground truth')\n",
    "    else:\n",
    "        plt.plot(trajectory.states.T[var_1], trajectory.states.T[var_2],label='Trajectory Prediction')\n",
    "        plt.plot(true_trajectory.states.T[var_1], true_trajectory.states.T[var_2],label='Ground Truth')\n",
    "\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title(\"Bio2 Test Trajectory Plot\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9065bd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(bench, var_1=0, var_2=-1, seed=100):\n",
    "    iv = get_init_states(bench, 1, seed)[0]\n",
    "    trajectory, true_trajectory = get_trajectories(bench, iv, param_dict[\"samp_period\"])\n",
    "    plot(trajectory, true_trajectory, var_1, var_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d3b8592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning GridSearchTuner: 100%|█████████████████████| 5/5 [00:00<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  0.82\n",
      "The average percentage error is 0.002%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning GridSearchTuner:  30%|██████              | 6/20 [00:09<00:25,  1.85s/it]/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_polynomial.py:479: RuntimeWarning: overflow encountered in multiply\n",
      "  np.multiply(\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/autokoopman/estimator/koopman.py:84: RuntimeWarning: invalid value encountered in matmul\n",
      "  return np.real(self._A @ obs.T).flatten()[: len(x)]\n",
      "Tuning GridSearchTuner:  30%|██████              | 6/20 [00:10<00:24,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Input X contains NaN.\n",
      "PolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "time taken:  10.379\n",
      "The average percentage error is 0.002%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning GridSearchTuner:  12%|██▍                 | 3/25 [00:06<00:45,  2.06s/it]/Users/b6062805/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:2559: RuntimeWarning: overflow encountered in multiply\n",
      "  s = (x.conj() * x).real\n",
      "/Users/b6062805/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:2560: RuntimeWarning: overflow encountered in reduce\n",
      "  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n",
      "Tuning GridSearchTuner: 100%|███████████████████| 25/25 [00:53<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  53.106\n",
      "The average percentage error is 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Tuning GridSearchTuner:   0%|                            | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepKoopman is using torch device 'cpu'\n",
      "DeepKoopman is using torch device 'cpu'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning GridSearchTuner:   0%|                            | 0/16 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jc/77d0pws90139vg5cc_fg8s_w5hwxm2/T/ipykernel_37609/3699260317.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# learn model from data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             experiment_results = auto_koopman(\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# list of trajectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0msampling_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"samp_period\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# sampling period of trajectory snapshots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/autokoopman/autokoopman.py\u001b[0m in \u001b[0;36mauto_koopman\u001b[0;34m(training_data, inputs_training_data, sampling_period, opt, max_opt_iter, max_epochs, n_splits, obs_type, cost_func, n_obs, rank, grid_param_slices, lengthscale, enc_dim, n_layers, torch_device, verbose)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"could not match a tuner to the string {opt}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnattempts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_opt_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_scoring_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;31m# pack results into out custom output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/autokoopman/tuner/gridsearch.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, nattempts, scoring_func)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0msampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/autokoopman/core/tuner.py\u001b[0m in \u001b[0;36mtune_sampling\u001b[0;34m(self, nattempts, scoring_func)\u001b[0m\n\u001b[1;32m    287\u001b[0m                     \u001b[0;31m# do the fit and scoring (select the best median)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m                     \u001b[0mprediction_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0miscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/autokoopman/estimator/deepkoopman.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrajectories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \"\"\"\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrajs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/autokoopman/estimator/deepkoopman.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trajs)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mpropagate_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0mrisk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"total_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obs_types = ['id', 'poly', 'rff', 'deep']\n",
    "store_data_heads([\"perc_error\", \"time(s)\",\"\"]*4)\n",
    "for i in range(1):\n",
    "    store_data([f\"Iteration {+1}\"])\n",
    "    for bench in benches:\n",
    "        result = [bench.name, \"\"]\n",
    "        for obs in obs_types:\n",
    "            np.random.seed(0)\n",
    "            param_dict = {\"train_size\":50,\"samp_period\":0.1,\"obs_type\":obs,\"opt\":\"grid\",\"n_obs\":200,\n",
    "                          \"grid_param_slices\":5,\"n_splits\":5,\"rank\":(1, 200, 40)}\n",
    "            # generate training data\n",
    "            training_data = get_training_data(bench, param_dict)\n",
    "            start = time.time()\n",
    "            # learn model from data\n",
    "            experiment_results = auto_koopman(\n",
    "                training_data,          # list of trajectories\n",
    "                sampling_period=param_dict[\"samp_period\"],    # sampling period of trajectory snapshots\n",
    "                obs_type=param_dict[\"obs_type\"],         # use Random Fourier Features Observables\n",
    "                opt=param_dict[\"opt\"],             # grid search to find best hyperparameters\n",
    "                n_obs=param_dict[\"n_obs\"],              # maximum number of observables to try\n",
    "                max_opt_iter=200,       # maximum number of optimization iterations\n",
    "                grid_param_slices=param_dict[\"grid_param_slices\"],# for grid search, number of slices for each parameter\n",
    "                n_splits=param_dict[\"n_splits\"],             # k-folds validation for tuning, helps stabilize the scoring\n",
    "                rank=param_dict[\"rank\"]       # rank range (start, stop, step) DMD hyperparameter\n",
    "            )\n",
    "            end = time.time()\n",
    "\n",
    "            mse = [-1]\n",
    "            perc_error = [-1]\n",
    "            try:\n",
    "                mse, perc_error = test_trajectories(bench, 10, param_dict[\"samp_period\"])\n",
    "            except ValueError:\n",
    "                print(\"can't compute for this setting\")\n",
    "\n",
    "            comp_time = round(end - start, 3)\n",
    "            print(\"time taken: \", comp_time)\n",
    "            print(f\"The average percentage error is {perc_error}%\" )\n",
    "\n",
    "            result.append(perc_error)\n",
    "            result.append(comp_time)\n",
    "            result.append(\"\")\n",
    "\n",
    "        store_data(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3bcb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
